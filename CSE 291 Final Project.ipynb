{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 291I Final Project\n",
    "Xuezheng Wang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "warping_field_path = 'outputs/warping_fields/'\n",
    "frame_path = '../default_input_video/'\n",
    "temp_frames_path = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    "    print(\"Using GPU!\")\n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    print(\"Using CPU!\")\n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_names = sorted(glob.glob(frame_path + \"*.png\"))\n",
    "frame_count = len(frame_names)\n",
    "print('number of frames:', frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFrame(path):\n",
    "    frame = torch.tensor(cv2.imread(path))\n",
    "    frame = torch.stack([frame[:,:,2], frame[:,:,1], frame[:,:,0]], dim=2)\n",
    "    frame = frame.float() / 255\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the dimensions of the frames\n",
    "sample_frame = readFrame(frame_names[0])\n",
    "frame_size = sample_frame.shape\n",
    "print('frame size:', frame_size)\n",
    "\n",
    "# Show the sample frame\n",
    "plt.imshow(sample_frame)\n",
    "plt.show()\n",
    "\n",
    "# Produce values that will be used later\n",
    "frame_width = frame_size[1]\n",
    "frame_height = frame_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optaining Warping Field from [Yu and Ramamorthi]\n",
    "The field is optained from another program included in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_optical_flow(flow, stride):\n",
    "    subsampled = np.zeros(np.array(flow.shape[:2]) // stride)\n",
    "    subsampled = np.reshape([subsampled, subsampled], [subsampled.shape[0], subsampled.shape[1], 2])\n",
    "#     print(subsampled.shape)\n",
    "\n",
    "    for i in range(subsampled.shape[0]):\n",
    "        for j in range(subsampled.shape[1]):\n",
    "            subsampled[i, j] = flow[i * stride, j * stride]\n",
    "\n",
    "    plt.quiver(subsampled[:,:,0], subsampled[:,:,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homography_to_flow(H, size):\n",
    "    # Create a meshgrid to transform\n",
    "    x = np.linspace(0, size[1] - 1, size[1])\n",
    "    y = np.linspace(0, size[0] - 1, size[0])\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    \n",
    "    # Calculate the x, y, and w of each point\n",
    "    w_new = xv * H[2, 0] + yv * H[2, 1] + H[2, 2]\n",
    "    x_new = xv * H[0, 0] + yv * H[0, 1] + H[0, 2]\n",
    "    y_new = xv * H[1, 0] + yv * H[1, 1] + H[1, 2]\n",
    "    \n",
    "    x_new = x_new / w_new\n",
    "    y_new = y_new / w_new\n",
    "    x_offset = x_new - xv\n",
    "    y_offset = y_new - yv\n",
    "    flow = np.dstack([x_offset, y_offset])\n",
    "    return flow\n",
    "\n",
    "def resample_flow(flow, new_shape):\n",
    "    flow = torch.from_numpy(flow)\n",
    "    flow = flow.permute(2, 0, 1).unsqueeze(0)\n",
    "    new_flow = F.interpolate(flow, new_shape, mode='bilinear')\n",
    "    \n",
    "    # Adjust for the scaling according to change in size\n",
    "    y_scale = new_shape[0] / flow.shape[2]\n",
    "    x_scale = new_shape[1] / flow.shape[3] \n",
    "    new_flow[:,0] *= y_scale\n",
    "    new_flow[:,0] *= x_scale\n",
    "    \n",
    "    return new_flow[0].permute(1, 2, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path to all the H_inv and warping fields\n",
    "path = 'outputs/warping_fields/'\n",
    "\n",
    "# \n",
    "# Load the warping field of a given frame idx\n",
    "#\n",
    "def load_warping_field(index):\n",
    "    # Make sure we have the index\n",
    "    assert index >= 0 and index < frame_count\n",
    "    \n",
    "    # Initialize the variables\n",
    "    H_inv = None\n",
    "    flow = None\n",
    "    \n",
    "    # Special treatment for frame 0\n",
    "    flow_shape = np.array([576, 960, 2]) # As generated by other code\n",
    "    if index == 0:\n",
    "        H_inv = np.eye(3)\n",
    "        flow = np.zeros(flow_shape) # Why are we using 448 + 2 * 64?\n",
    "    else:\n",
    "        H_inv_path = path + str(index).zfill(5) + '_H_inv.npy'\n",
    "        H_inv = np.load(H_inv_path)\n",
    "\n",
    "        flow_path = path + str(index).zfill(5) + '.npy'\n",
    "        flow = np.load(flow_path)\n",
    "        \n",
    "        # Convert optical flow space from [-1, 1] to [0, width/height]\n",
    "        flow[:, :, 0] *= float(flow_shape[0]) / 2\n",
    "        flow[:, :, 1] *= float(flow_shape[1]) / 2\n",
    "        \n",
    "    # Combine the optical flow and the homography\n",
    "    H_flow = homography_to_flow(H_inv, flow_shape)\n",
    "    combined_flow = H_flow + flow\n",
    "        \n",
    "    # Resample the optical flow to frame space\n",
    "    # There's 64 paddings around the edge\n",
    "    padding = 64\n",
    "    frame_flow = resample_flow(combined_flow[padding:-padding, padding:-padding], frame_size[:2])\n",
    "    \n",
    "#     plot_optical_flow(combined_flow, 30)\n",
    "#     plot_optical_flow(frame_flow, 30)\n",
    "    \n",
    "    return frame_flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_flow(img, flow):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    # Create a meshgrid\n",
    "    y_pos = torch.linspace(-1, 1, height) # This might be wrong\n",
    "    x_pos = torch.linspace(-1, 1, width)\n",
    "    y_grid = y_pos.view(1, -1, 1).expand(-1, -1, width)\n",
    "    x_grid = x_pos.view(1, 1, -1).expand(-1, height, -1)\n",
    "    grid = torch.stack([x_grid, y_grid], dim=3)\n",
    "    \n",
    "    # Transform the grid\n",
    "    flow[:, :, 0] /= float(height) / 2 # Check this as well\n",
    "    flow[:, :, 1] /= float(width) / 2\n",
    "    grid_flow = grid + flow.unsqueeze(0)\n",
    "    \n",
    "    # Reshape img\n",
    "    img_reshape = img.permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    # Sample the image\n",
    "    result = F.grid_sample(img_reshape, grid_flow.float())\n",
    "    return result[0].permute(1, 2, 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Try to apply flow to the frames, then output the results\n",
    "output_imgs = []\n",
    "for frame_id in range(frame_count):\n",
    "    # Read the image\n",
    "    this_frame = readFrame(frame_names[frame_id])\n",
    "    \n",
    "    # Generate the flow from original frame to sample frame\n",
    "    flow = load_warping_field(frame_id)\n",
    "    \n",
    "    # Warp the frame\n",
    "    img = apply_flow(this_frame, flow)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    \n",
    "    output_imgs.append(img)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to write the images out as video\n",
    "out = cv2.VideoWriter('test1.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 24, (frame_width, frame_height))\n",
    "for i in range(len(output_imgs)):\n",
    "    np_img = np.uint8(output_imgs[i] * 255)\n",
    "    np_img = np.dstack([np_img[:,:,2], np_img[:,:,1], np_img[:,:,0]])\n",
    "    out.write(np_img)\n",
    "out.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RAFT for optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "staProj",
   "language": "python",
   "name": "staproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
